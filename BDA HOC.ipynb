{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff0c4b1-8c57-4bbe-bc4c-160ec3a3f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('human activity recognition') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d05e3b4-a87a-4706-af12-72197ae479a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://65d2368ce795:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>human activity recognition</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f510675d3f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe34a328-a57c-41f0-99f1-32ffd2e53730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (spark.read.format(\"csv\").option('header', 'true').load(\"Phones_accelerometer.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60ef8bb-0974-4742-84d9-738ee65bc18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------------+----------+------------------+--------+----+------+--------+-----+\n",
      "|Index| Arrival_Time|      Creation_Time|         x|                 y|       z|User| Model|  Device|   gt|\n",
      "+-----+-------------+-------------------+----------+------------------+--------+----+------+--------+-----+\n",
      "|    0|1424696633908|1424696631913248572| -5.958191|         0.6880646|8.135345|   a|nexus4|nexus4_1|stand|\n",
      "|    1|1424696633909|1424696631918283972|  -5.95224|         0.6702118|8.136536|   a|nexus4|nexus4_1|stand|\n",
      "|    2|1424696633918|1424696631923288855|-5.9950867|0.6535491999999999|8.204376|   a|nexus4|nexus4_1|stand|\n",
      "+-----+-------------+-------------------+----------+------------------+--------+----+------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e119dd51-1baa-40aa-a19a-45b7841447f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Index', 'string'),\n",
       " ('Arrival_Time', 'string'),\n",
       " ('Creation_Time', 'string'),\n",
       " ('x', 'string'),\n",
       " ('y', 'string'),\n",
       " ('z', 'string'),\n",
       " ('User', 'string'),\n",
       " ('Model', 'string'),\n",
       " ('Device', 'string'),\n",
       " ('gt', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c957a196-26eb-4da2-85c6-1bbc13597415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------+----------+---------+-----+\n",
      "|     Arrival_Time|       Creation_Time|         x|         y|        z|   gt|\n",
      "+-----------------+--------------------+----------+----------+---------+-----+\n",
      "|1.424696633908E12|1.424696631913248...| -5.958191| 0.6880646| 8.135345|stand|\n",
      "|1.424696633909E12|1.424696631918284...|  -5.95224| 0.6702118| 8.136536|stand|\n",
      "|1.424696633918E12|1.424696631923288...|-5.9950867| 0.6535492| 8.204376|stand|\n",
      "|1.424696633919E12|1.424696631928385...|-5.9427185| 0.6761627| 8.128204|stand|\n",
      "|1.424696633929E12|1.424696631933420...| -5.991516|0.64164734| 8.135345|stand|\n",
      "|1.424696633929E12|1.424696631938456...| -5.965332| 0.6297455| 8.128204|stand|\n",
      "|1.424696633938E12|1.424696631943522...| -5.991516| 0.6356964|  8.16272|stand|\n",
      "|1.424696633939E12|1.424696631948496...| -5.915344|0.63093567| 8.105591|stand|\n",
      "|1.424696633951E12|1.424696631953592...| -5.984375| 0.6940155| 8.067505|stand|\n",
      "|1.424696633952E12|1.424696631960428...| -5.937958|0.71543884| 8.090118|stand|\n",
      "|1.424696633959E12|1.424696631963663...| -5.902252| 0.6678314| 8.069885|stand|\n",
      "| 1.42469663396E12|1.424696631968912...|-5.9498596|0.68092346| 8.119873|stand|\n",
      "|1.424696633966E12|1.424696631973734...|-5.9796143| 0.7416229|8.0841675|stand|\n",
      "|1.424696633972E12|1.424696631978769...|-5.9617615|0.71424866| 8.155579|stand|\n",
      "|1.424696633978E12|1.424696631983805...|  -5.95343| 0.7130585| 8.153198|stand|\n",
      "|1.424696633981E12|1.424696631988840...|-5.8665466| 0.7344818|  8.10083|stand|\n",
      "|1.424696633989E12|1.424696631993875...| -5.901062| 0.7582855| 8.081787|stand|\n",
      "|1.424696633991E12|1.424696631999064...|-5.8713074| 0.7190094| 8.192474|stand|\n",
      "|1.424696634003E12|1.424696632003946...| -5.932007|0.67259216| 8.185333|stand|\n",
      "|1.424696634004E12|1.424696632010447...| -5.895111| 0.6797333| 8.132965|stand|\n",
      "+-----------------+--------------------+----------+----------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "dataset1 = df1.select(col('Arrival_Time').cast('double'),\n",
    "                         col('Creation_Time').cast('double'),\n",
    "                         col('x').cast('float'),\n",
    "                         col('y').cast('float'),\n",
    "                         col('z').cast('float'),\n",
    "                         col('gt'),\n",
    "                         )\n",
    "dataset1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56628dc8-753b-4ea4-8a84-7b4edc763a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "dataset1 = StringIndexer(\n",
    "    inputCol='gt', \n",
    "    outputCol='gt_index', \n",
    "    handleInvalid='keep').fit(dataset1).transform(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffaabe46-3553-4d0e-8897-8340b02ea209",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = dataset1.drop('gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "975ac185-8e3e-4afc-b876-66977d9c0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all the features with VectorAssembler\n",
    "required_features = ['Arrival_Time',\n",
    "                     'Creation_Time',\n",
    "                     'x',\n",
    "                     'y',\n",
    "                     'z']\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
    "transformed_data = assembler.transform(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb73bc35-337b-48f2-a800-ea16e8418cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------+----------+---------+--------+--------------------+\n",
      "|     Arrival_Time|       Creation_Time|         x|         y|        z|gt_index|            features|\n",
      "+-----------------+--------------------+----------+----------+---------+--------+--------------------+\n",
      "|1.424696633908E12|1.424696631913248...| -5.958191| 0.6880646| 8.135345|     2.0|[1.424696633908E1...|\n",
      "|1.424696633909E12|1.424696631918284...|  -5.95224| 0.6702118| 8.136536|     2.0|[1.424696633909E1...|\n",
      "|1.424696633918E12|1.424696631923288...|-5.9950867| 0.6535492| 8.204376|     2.0|[1.424696633918E1...|\n",
      "|1.424696633919E12|1.424696631928385...|-5.9427185| 0.6761627| 8.128204|     2.0|[1.424696633919E1...|\n",
      "|1.424696633929E12|1.424696631933420...| -5.991516|0.64164734| 8.135345|     2.0|[1.424696633929E1...|\n",
      "|1.424696633929E12|1.424696631938456...| -5.965332| 0.6297455| 8.128204|     2.0|[1.424696633929E1...|\n",
      "|1.424696633938E12|1.424696631943522...| -5.991516| 0.6356964|  8.16272|     2.0|[1.424696633938E1...|\n",
      "|1.424696633939E12|1.424696631948496...| -5.915344|0.63093567| 8.105591|     2.0|[1.424696633939E1...|\n",
      "|1.424696633951E12|1.424696631953592...| -5.984375| 0.6940155| 8.067505|     2.0|[1.424696633951E1...|\n",
      "|1.424696633952E12|1.424696631960428...| -5.937958|0.71543884| 8.090118|     2.0|[1.424696633952E1...|\n",
      "|1.424696633959E12|1.424696631963663...| -5.902252| 0.6678314| 8.069885|     2.0|[1.424696633959E1...|\n",
      "| 1.42469663396E12|1.424696631968912...|-5.9498596|0.68092346| 8.119873|     2.0|[1.42469663396E12...|\n",
      "|1.424696633966E12|1.424696631973734...|-5.9796143| 0.7416229|8.0841675|     2.0|[1.424696633966E1...|\n",
      "|1.424696633972E12|1.424696631978769...|-5.9617615|0.71424866| 8.155579|     2.0|[1.424696633972E1...|\n",
      "|1.424696633978E12|1.424696631983805...|  -5.95343| 0.7130585| 8.153198|     2.0|[1.424696633978E1...|\n",
      "|1.424696633981E12|1.424696631988840...|-5.8665466| 0.7344818|  8.10083|     2.0|[1.424696633981E1...|\n",
      "|1.424696633989E12|1.424696631993875...| -5.901062| 0.7582855| 8.081787|     2.0|[1.424696633989E1...|\n",
      "|1.424696633991E12|1.424696631999064...|-5.8713074| 0.7190094| 8.192474|     2.0|[1.424696633991E1...|\n",
      "|1.424696634003E12|1.424696632003946...| -5.932007|0.67259216| 8.185333|     2.0|[1.424696634003E1...|\n",
      "|1.424696634004E12|1.424696632010447...| -5.895111| 0.6797333| 8.132965|     2.0|[1.424696634004E1...|\n",
      "+-----------------+--------------------+----------+----------+---------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e728cc-a868-4ff7-908a-46b2c09a4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13062475"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2492790-96b7-4159-a986-2f54f4d3267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------+----------+---------+--------+\n",
      "|     Arrival_Time|       Creation_Time|         x|         y|        z|gt_index|\n",
      "+-----------------+--------------------+----------+----------+---------+--------+\n",
      "|1.424696633908E12|1.424696631913248...| -5.958191| 0.6880646| 8.135345|     2.0|\n",
      "|1.424696633909E12|1.424696631918284...|  -5.95224| 0.6702118| 8.136536|     2.0|\n",
      "|1.424696633918E12|1.424696631923288...|-5.9950867| 0.6535492| 8.204376|     2.0|\n",
      "|1.424696633919E12|1.424696631928385...|-5.9427185| 0.6761627| 8.128204|     2.0|\n",
      "|1.424696633929E12|1.424696631933420...| -5.991516|0.64164734| 8.135345|     2.0|\n",
      "|1.424696633929E12|1.424696631938456...| -5.965332| 0.6297455| 8.128204|     2.0|\n",
      "|1.424696633938E12|1.424696631943522...| -5.991516| 0.6356964|  8.16272|     2.0|\n",
      "|1.424696633939E12|1.424696631948496...| -5.915344|0.63093567| 8.105591|     2.0|\n",
      "|1.424696633951E12|1.424696631953592...| -5.984375| 0.6940155| 8.067505|     2.0|\n",
      "|1.424696633952E12|1.424696631960428...| -5.937958|0.71543884| 8.090118|     2.0|\n",
      "|1.424696633959E12|1.424696631963663...| -5.902252| 0.6678314| 8.069885|     2.0|\n",
      "| 1.42469663396E12|1.424696631968912...|-5.9498596|0.68092346| 8.119873|     2.0|\n",
      "|1.424696633966E12|1.424696631973734...|-5.9796143| 0.7416229|8.0841675|     2.0|\n",
      "|1.424696633972E12|1.424696631978769...|-5.9617615|0.71424866| 8.155579|     2.0|\n",
      "|1.424696633978E12|1.424696631983805...|  -5.95343| 0.7130585| 8.153198|     2.0|\n",
      "|1.424696633981E12|1.424696631988840...|-5.8665466| 0.7344818|  8.10083|     2.0|\n",
      "|1.424696633989E12|1.424696631993875...| -5.901062| 0.7582855| 8.081787|     2.0|\n",
      "|1.424696633991E12|1.424696631999064...|-5.8713074| 0.7190094| 8.192474|     2.0|\n",
      "|1.424696634003E12|1.424696632003946...| -5.932007|0.67259216| 8.185333|     2.0|\n",
      "|1.424696634004E12|1.424696632010447...| -5.895111| 0.6797333| 8.132965|     2.0|\n",
      "+-----------------+--------------------+----------+----------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994551f0-2311-48df-9df8-b193e39d6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = transformed_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf005243-6af4-4de7-ba1e-acf6b48ea4bc",
   "metadata": {},
   "source": [
    "import time\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol='gt_index', \n",
    "                            featuresCol='features',\n",
    "                            )\n",
    "start_time = time.perf_counter()\n",
    "model = rf.fit(training_data)\n",
    "predictions = model.transform(test_data)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='gt_index', \n",
    "    predictionCol='prediction', \n",
    "    metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Accuracy = ', accuracy)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"The time taken to train the data is: %0.3f seconds\" %training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8368fbf-ecdc-43a7-bf14-dc1a65d7e720",
   "metadata": {},
   "source": [
    "import time\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol='gt_index', \n",
    "                            featuresCol='features',\n",
    "                            maxDepth = 5)\n",
    "start_time = time.perf_counter()\n",
    "model = rf.fit(training_data)\n",
    "predictions = model.transform(test_data)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='gt_index', \n",
    "    predictionCol='prediction', \n",
    "    metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Accuracy = ', accuracy)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"The time taken to train the data is: %0.3f seconds\" %training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af066f8d-2e3d-47b9-be3a-a3d4db5bed06",
   "metadata": {},
   "source": [
    "import time\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol='gt_index', \n",
    "                            featuresCol='features',\n",
    "                            maxDepth = 10)\n",
    "start_time = time.perf_counter()\n",
    "model = rf.fit(training_data)\n",
    "predictions = model.transform(test_data)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='gt_index', \n",
    "    predictionCol='prediction', \n",
    "    metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Accuracy = ', accuracy)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"The time taken to train the data is: %0.3f seconds\" %training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c97b2d-8c23-47bf-8a0d-2c46b7ae1355",
   "metadata": {},
   "source": [
    "import time\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol='gt_index', \n",
    "                            featuresCol='features',\n",
    "                           )\n",
    "start_time = time.perf_counter()\n",
    "model = gbt.fit(training_data)\n",
    "predictions = model.transform(test_data)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='gt_index', \n",
    "    predictionCol='prediction', \n",
    "    metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Accuracy = ', accuracy)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"The time taken to train the data is: %0.3f seconds\" %training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd8b96b-773e-4d43-9fb9-c674cd4dcc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_15997/1549475610.py\", line 6, in <cell line: 6>\n",
      "    lrModel = lr.fit(training_data)\n",
      "  File \"/usr/local/spark/python/pyspark/ml/base.py\", line 161, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/usr/local/spark/python/pyspark/ml/wrapper.py\", line 335, in _fit\n",
      "    java_model = self._fit_java(dataset)\n",
      "  File \"/usr/local/spark/python/pyspark/ml/wrapper.py\", line 332, in _fit_java\n",
      "    return self._java_obj.fit(dataset._jdf)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/usr/local/spark/python/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 6\u001b[0m lrModel \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lrModel\u001b[38;5;241m.\u001b[39mtransform(test_data)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:335\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m--> 335\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:332\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2003\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2000\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2003\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py:538\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    532\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    533\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    535\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    539\u001b[0m }\n\u001b[1;32m    541\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py:281\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py:288\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py:402\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'gt_index', maxIter=10)\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "lrModel = lr.fit(training_data)\n",
    "predictions = lrModel.transform(test_data)\n",
    "\n",
    "# Evaluate our model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='gt_index', \n",
    "    predictionCol='prediction', \n",
    "    metricName='accuracy')\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Accuracy = ', accuracy)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "training_time = end_time - start_time\n",
    "print(\"The time taken to train the data is: %0.3f seconds\" %training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12ed36-6cd8-49a6-b922-34e3c9b67b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
